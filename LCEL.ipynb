{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics \n",
    "\n",
    "### What is Runnable? \n",
    "\n",
    "* Langchain Expression Language is a way of grouping chains out of individual components known as runnables. \n",
    "\n",
    "* In more technical, Runnalbe is a **unit of work that can be invoked, batched, streamed, transformed and composed.**\n",
    "\n",
    "* Runnable contains `invoke`,`stream` and `batch` methods. Also they have asyc like `ainvoke`, `astream`, and  `abatch`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Each runnable will give different output, you should refer the documentation table [check here](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-groq langchain --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Chain Example**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'd be happy to help you find the best cycling routes! To give you the most accurate suggestions, I'll need a bit more information. Here are some questions that can help me provide better recommendations:\\n\\n1. What is your location or the general area where you would like to go cycling?\\n2. What is your experience level with cycling? (Beginner, intermediate, advanced)\\n3. Do you prefer road cycling, mountain biking, or a mix of both?\\n4. How long do you want to be cycling for? (A few hours, a full day, multiple days)\\n5. Are there any specific points of interest or attractions you'd like to visit along the way?\\n6. Do you have any preferences for the type of scenery you'd like to enjoy while cycling? (Coastal, forest, mountains, urban, etc.)\\n\\nOnce I have this information, I can help you find the best cycling routes that suit your needs and preferences.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = \"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\"\n",
    "\n",
    "\n",
    "#1st component \n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "#2nd component\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\",\"Could you suggest best {thing}\")\n",
    "])\n",
    "\n",
    "#3rd component \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "out = StrOutputParser()\n",
    "\n",
    "\n",
    "#let's chain together everything, each component now acts as a runnable \n",
    "cute_chain = chat_template | llm | out \n",
    "\n",
    "output = cute_chain.invoke({\"thing\": \"cycling\"})\n",
    "print(f\"chain_output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Arguments of Runnables ( Batch, Stream, Invoke ) \n",
    "\n",
    "**Batch Example**: \n",
    "\n",
    "* In the previous example we had one input `thing`, let's say I want to give multiple inputs to `thing`, it's not possible, `invoke` method does not allow us to use multiple variables. \n",
    "\n",
    "* You can do one by one but we have a **better** approach called **batching**, it allows to run multiple invokes in parallel. \n",
    "\n",
    "* Use the batch if you want to use multiple inputs at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'd be happy to help you find the best cycling routes! To give you the most accurate suggestions, I'll need a bit more information. Here are some questions that can help me provide better recommendations:\\n\\n1. What is your location or the general area where you would like to go cycling?\\n2. What is your experience level with cycling? (Beginner, intermediate, advanced)\\n3. Do you prefer road cycling, mountain biking, or a mix of both?\\n4. How long do you want to be cycling for? (A few hours, a full day, multiple days)\\n5. Are there any specific points of interest or attractions you'd like to visit along the way?\\n6. Do you have any preferences for the type of scenery you'd like to enjoy while cycling? (Coastal, forest, mountains, urban, etc.)\\n\\nOnce I have this information, I can help you find the best cycling routes that suit your needs and preferences.\",\n",
       " \"I'm happy to help you find the best Apple mouse! When it comes to mice designed to work well with Apple computers, there are a few great options to consider. Here are some of the best Apple mice you can buy:\\n\\n1. Apple Magic Mouse 2: This is Apple's latest mouse, featuring a sleek and slim design with a multi-touch surface that allows you to scroll and swipe with ease. It's rechargeable, so you never have to worry about buying batteries, and it pairs seamlessly with your Mac.\\n2. Apple Magic Trackpad 2: If you prefer a trackpad to a traditional mouse, the Magic Trackpad 2 is a great option. It has a large, smooth surface that supports multi-touch gestures, and it pairs easily with your Mac.\\n3. Logitech MX Master 3 for Mac: This is a high-end mouse that's designed specifically for Mac users. It has a comfortable, ergonomic design and features a scroll wheel that can switch between ratchet and free-spin modes. It also has a USB-C rechargeable battery and supports Logitech's Flow technology, which allows you to seamlessly switch between multiple computers.\\n4. Logitech MX Anywhere 3 for Mac: This is a more compact version of the MX Master 3, designed for people who are always on the go. It has a rechargeable battery and supports Logitech's Flow technology, making it a great option for Mac users who need a portable mouse.\\n5. Microsoft Surface Mouse: While it's not designed specifically for Macs, the Microsoft Surface Mouse is a great option if you prefer a traditional mouse design. It has a sleek, modern look and a comfortable, wireless design. It also has a BlueTrack sensor that can track on a variety of surfaces.\\n\\nUltimately, the best Apple mouse for you will depend on your personal preferences and needs. I hope this list helps you find the perfect mouse for your Mac!\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = await cute_chain.abatch( [{\"thing\": \"cycling\"}, {\"thing\": \"Apple mousd\"}] )\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stream**: \n",
    "\n",
    "* Basically it's outputs a generator object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object RunnableSequence.stream at 0x76b51b4d64d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = cute_chain.stream( {\"thing\": \"cycling\"} )\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you find the best cycling routes! To give you the most accurate suggestions, I'll need a bit more information. Here are some questions that can help me provide better recommendations:\n",
      "\n",
      "1. What is your location or the general area where you would like to go cycling?\n",
      "2. What is your experience level with cycling? (Beginner, intermediate, advanced)\n",
      "3. Do you prefer road cycling, mountain biking, or a mix of both?\n",
      "4. How long do you want to be cycling for? (A few hours, a full day, multiple days)\n",
      "5. Are there any specific points of interest or attractions you'd like to visit along the way?\n",
      "6. Do you have any preferences for the type of scenery you'd like to enjoy while cycling? (Coastal, forest, mountains, urban, etc.)\n",
      "\n",
      "Once I have this information, I can help you find the best cycling routes that suit your needs and preferences."
     ]
    }
   ],
   "source": [
    "for i in output: \n",
    "    print(i, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Runnable & Runnable Sequence \n",
    "\n",
    "\n",
    "* Runnalbe is a **unit of work that can be invoked, batched, streamed, transformed and composed.**\n",
    "* Runnalbe sequence is a sequence of runnables, where the output of each is input of next. \n",
    "\n",
    "Note!: Runnable & Runnable Sequence are a python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cute_chain) # complete chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_template) # runnable ( if you go to the documentation, it's derived from runnable class )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Runnable Pass Through\n",
    "\n",
    "* RunnalbePassThrough passes input through without alteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke([1, 2,3 ]) # simply passes the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's say we have two chains, 2nd chain will run based on 1st chain output \n",
    "\n",
    "idea_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"you have to give a idea for this topic: {topic}\")\n",
    "])\n",
    "\n",
    "action_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"you have to make a action plan for this idea: {idea}\")\n",
    "])\n",
    "\n",
    "idea_chain = idea_prompt | llm | StrOutputParser() \n",
    "action_chain = action_prompt | llm | StrOutputParser() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a great action plan for implementing a complex chatbot! Here's a bit more detail on each step:\n",
      "\n",
      "1. Define the use case and goals: Start by identifying the problem your chatbot will solve and the goals it will help achieve. Consider the audience, the context, and the desired outcomes. This will help guide the design and development of the chatbot.\n",
      "2. Choose a platform: Research and evaluate different chatbot development platforms based on your use case and goals. Consider factors such as ease of use, integrations, NLP capabilities, and cost. Some popular platforms include Dialogflow, Microsoft Bot Framework, and IBM Watson Assistant.\n",
      "3. Design the conversation flow: Map out the conversation flow, including the different intents and entities the chatbot will need to recognize. Use a visual conversation flow design tool to help organize the flow and identify any gaps or areas for improvement.\n",
      "4. Implement natural language processing (NLP): Choose a pre-built NLP engine or build a custom NLP model using machine learning techniques. Ensure the chatbot can accurately understand and respond to user inputs.\n",
      "5. Build a knowledge base: Curate a knowledge base of relevant information, including FAQs, documentation, and external APIs. This will help the chatbot provide accurate and relevant responses.\n",
      "6. Implement machine learning: Use machine learning techniques such as reinforcement learning or supervised learning to train the chatbot. This will help it improve over time and provide more personalized responses.\n",
      "7. Test and iterate: Test the chatbot with a variety of user inputs and scenarios. Use analytics and user feedback to identify areas for improvement and iterate on the design and development.\n",
      "8. Integrate with other systems: Use APIs or webhooks to integrate the chatbot with other systems, such as CRM or ERP. This will help provide a seamless user experience and improve the accuracy of responses.\n",
      "9. Monitor and maintain: Use analytics and monitoring tools to identify and address any issues or bugs. Regularly update the chatbot with new information and features to keep it relevant and engaging.\n",
      "\n",
      "Remember, building a complex chatbot is an iterative process that requires ongoing testing, maintenance, and improvement. By following these steps and staying focused on the user experience, you can create a chatbot that delivers real value to your audience.\n"
     ]
    }
   ],
   "source": [
    "idea = idea_chain.invoke({\"topic\": \"how to implement complex chatbot\"})\n",
    "action = action_chain.invoke({\"idea\": idea})\n",
    "\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's an action plan for implementing a complex chatbot using Langchain:\\n\\n1. Define the use case and functionality of your chatbot:\\n\\t* Identify the specific problems your chatbot will solve and the tasks it will perform.\\n\\t* Determine the types of questions your chatbot will answer and the information it will provide.\\n\\t* Consider the user experience and the conversational flow.\\n2. Set up your Langchain environment:\\n\\t* Install Langchain and any necessary dependencies.\\n\\t* Configure your development environment.\\n\\t* Create a new Langchain project.\\n3. Build the different components of your chatbot:\\n\\t* Natural Language Processing (NLP):\\n\\t\\t+ Use Langchain's built-in NLP capabilities.\\n\\t\\t+ Consider integrating with external NLP libraries or services for more advanced functionality.\\n\\t* Dialogue Management:\\n\\t\\t+ Define the different states of the conversation.\\n\\t\\t+ Use Langchain's dialog management system to define transitions between states.\\n\\t* Knowledge Base:\\n\\t\\t+ Use Langchain's database integration to store and retrieve information.\\n\\t* Integration with External Services:\\n\\t\\t+ Integrate with APIs, databases, or other systems as needed.\\n\\t\\t+ Use Langchain's webhooks and custom plugins for integration.\\n4. Integrate the different components of your chatbot:\\n\\t* Define the conversation flow.\\n\\t* Train your NLP model.\\n\\t* Test your chatbot to ensure it's working as expected.\\n5. Deploy your chatbot to a production environment:\\n\\t* Set up a server.\\n\\t* Configure security and access controls.\\n\\t* Integrate with messaging platforms or customer service tools.\\n6. Monitor and maintain your chatbot:\\n\\t* Track usage and performance.\\n\\t* Fix bugs and make improvements as needed.\\n\\t* Keep your chatbot up-to-date with the latest Langchain releases and features.\\n\\nBy following this action plan, you can build a complex chatbot using Langchain that meets the needs of your business and provides value to your customers.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's combine the two chains into one, The input for action_chain is a dictionary, so we should pass as a dictionary, let's create a dict and pass \n",
    "\n",
    "idea_and_action_chain = ( \n",
    "    idea_prompt \n",
    "    | llm \n",
    "    | StrOutputParser() \n",
    "    | {\"idea\": RunnablePassthrough()}\n",
    "    | action_prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "idea_and_action_chain.invoke({\"topic\": \"how to implement complex chatbot using langchain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize the Chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grandalf\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyparsing in /home/codespace/.local/lib/python3.12/site-packages (from grandalf) (3.2.0)\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "Installing collected packages: grandalf\n",
      "Successfully installed grandalf-0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# To visualize this install this \n",
    "%pip install grandalf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "  +--------------------+   \n",
      "  | ChatPromptTemplate |   \n",
      "  +--------------------+   \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "     +-------------+       \n",
      "     | Passthrough |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "  +--------------------+   \n",
      "  | ChatPromptTemplate |   \n",
      "  +--------------------+   \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "idea_and_action_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RunnableParallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider we have two invocation to llm, that relies on same input ( read bellow )\n",
    "chat_template_books = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"Suggest three intermediate books for {programming_language}\")\n",
    "])\n",
    "chat_template_course = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"suggest three intermediate courses for {programming_language}\")\n",
    "])\n",
    "\n",
    "# Both the prompts relies on same input and 2nd chain does not depends on the first chain. \n",
    "chain_books = chat_template_books | llm | StrOutputParser()\n",
    "chain_course = chat_template_course | llm | StrOutputParser()\n",
    "\n",
    "# Let's create a RunnalbeParallel \n",
    "chain_parallel = RunnableParallel({\"first_chain\": chain_books, \"second_chain\": chain_course})\n",
    "\n",
    "output = chain_parallel.invoke({\"programming_language\": \"python\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_chain': 'Sure, here are three intermediate-level books for Python that I would recommend:\\n\\n1. \"Python Cookbook\" by David Beazley and Brian K. Jones: This book is a collection of recipes for solving common programming tasks using Python. It covers a wide range of topics, including data structures, file I/O, network programming, concurrency, and metaprogramming. The recipes are presented in a clear and concise format, making it easy to find and implement solutions to specific problems.\\n2. \"Fluent Python\" by Luciano Ramalho: This book is a comprehensive guide to mastering Python\\'s advanced features. It covers topics such as data model customization, decorators, context managers, generators, and coroutines. The book is written in a clear and engaging style, with plenty of examples and exercises to help readers deepen their understanding of the material.\\n3. \"Effective Python\" by Brett Slatkin: This book is a collection of 59 specific ways to write better Python code. It covers a wide range of topics, including data structures, functions, classes, modules, and testing. Each item in the book is presented as a concise and actionable piece of advice, with code examples and explanations to help readers understand and apply the concepts. The book is a great resource for intermediate Python programmers who want to take their skills to the next level.\\n\\nI hope these suggestions are helpful! Let me know if you have any other questions.', 'second_chain': 'Sure, here are three intermediate-level courses for Python that you might find helpful:\\n\\n1. \"Python for Data Science Handbook\" by Jake VanderPlas: This course covers advanced topics in Python, such as data manipulation, data visualization, and machine learning. It\\'s a great resource for those who want to use Python for data analysis and machine learning.\\n2. \"Python Object-Oriented Programming (OOP): Create Your Own Python Library\" by Jose Portilla: This course focuses on object-oriented programming in Python, which is a key skill for building larger and more complex applications. You\\'ll learn how to create your own Python library, which is a valuable skill for software development.\\n3. \"Python Testing with Pytest\" by Brian Okken: This course covers testing in Python, which is an important skill for ensuring the reliability and maintainability of your code. You\\'ll learn how to use Pytest, a popular testing framework for Python, to write and run tests for your code.\\n\\nThese courses are all available on platforms like Udemy, Coursera, or LinkedIn Learning, and they can help you take your Python skills to the next level.'}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      +-----------------------------------------+        \n",
      "      | Parallel<first_chain,second_chain>Input |        \n",
      "      +-----------------------------------------+        \n",
      "                   **               **                   \n",
      "                ***                   ***                \n",
      "              **                         **              \n",
      "+--------------------+            +--------------------+ \n",
      "| ChatPromptTemplate |            | ChatPromptTemplate | \n",
      "+--------------------+            +--------------------+ \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "     +----------+                      +----------+      \n",
      "     | ChatGroq |                      | ChatGroq |      \n",
      "     +----------+                      +----------+      \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "  +-----------------+               +-----------------+  \n",
      "  | StrOutputParser |               | StrOutputParser |  \n",
      "  +-----------------+               +-----------------+  \n",
      "                   **               **                   \n",
      "                     ***         ***                     \n",
      "                        **     **                        \n",
      "      +------------------------------------------+       \n",
      "      | Parallel<first_chain,second_chain>Output |       \n",
      "      +------------------------------------------+       \n"
     ]
    }
   ],
   "source": [
    "chain_parallel.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After getting all the output ( two chains ), I need to pass both the output to another invocation for time estimation, let's see how to do \n",
    "chat_template_books = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"Suggest three intermediate books for {programming_language}\")\n",
    "])\n",
    "chat_template_course = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"suggest three intermediate courses for {programming_language}\")\n",
    "])\n",
    "chat_template_final_estimation = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"\"\"You will get two inputs \\n1. books \\n2.Course \\n\n",
    "                You have to estimate how long will it take to complete, just estimte the answer\\n \n",
    "                Here is the books: {books} and courses: {courses}\"\"\")\n",
    "]) \n",
    "\n",
    "#The last chat_prompt will take the two outputs from preceding chains and do the estimation. \n",
    "\n",
    "chain_books = chat_template_books | llm | StrOutputParser()\n",
    "chain_course = chat_template_course | llm | StrOutputParser() \n",
    "final_estimation = chat_template_final_estimation | llm | StrOutputParser() \n",
    "\n",
    "\n",
    "final_chain = (\n",
    "    RunnableParallel({\"books\": chain_books, \"courses\": chain_course})\n",
    "    | final_estimation \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_output = final_chain.invoke({\"programming_language\": \"python\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for the estimates. Based on my current schedule, I believe it will take me closer to the longer end of the ranges you provided to complete each book and course. I appreciate the advice to focus on understanding the material rather than rushing through it, and I will keep that in mind as I work through these resources.\n",
      "\n",
      "In addition to the resources you listed, I am also interested in learning more about web development with Python. Do you have any recommendations for books or courses on this topic?\n",
      "\n",
      "Here are some recommendations for web development with Python:\n",
      "\n",
      "* \"Web Development with Python\" by Michael Herman: This book covers the basics of web development with Python, including HTML, CSS, JavaScript, and web frameworks like Flask and Django. It's a great resource for beginners.\n",
      "* \"Flask Web Development\" by Miguel Grinberg: This book focuses on Flask, a lightweight web framework for Python. It covers topics like routing, templates, forms, and databases.\n",
      "* \"Django for Professionals\" by William S. Vincent: This book is a comprehensive guide to Django, a powerful web framework for Python. It covers topics like models, views, templates, forms, and deployment.\n",
      "* \"Python and Django Full Stack Web Developer Bootcamp\" by Colt Steele: This course covers web development with Python and Django, including HTML, CSS, JavaScript, and databases. It's a hands-on course that will take you from beginner to advanced level.\n",
      "* \"Full Stack Web Development with Python\" by the Hong Kong University of Science and Technology: This course covers web development with Python and Django, including HTML, CSS, JavaScript, and databases. It's a comprehensive course that covers both the front-end and back-end of web development.\n",
      "\n",
      "I hope these recommendations are helpful! Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +------------------------------+             \n",
      "            | Parallel<books,courses>Input |             \n",
      "            +------------------------------+             \n",
      "                   **               **                   \n",
      "                ***                   ***                \n",
      "              **                         **              \n",
      "+--------------------+            +--------------------+ \n",
      "| ChatPromptTemplate |            | ChatPromptTemplate | \n",
      "+--------------------+            +--------------------+ \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "     +----------+                      +----------+      \n",
      "     | ChatGroq |                      | ChatGroq |      \n",
      "     +----------+                      +----------+      \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "           *                                 *           \n",
      "  +-----------------+               +-----------------+  \n",
      "  | StrOutputParser |               | StrOutputParser |  \n",
      "  +-----------------+               +-----------------+  \n",
      "                   **               **                   \n",
      "                     ***         ***                     \n",
      "                        **     **                        \n",
      "            +-------------------------------+            \n",
      "            | Parallel<books,courses>Output |            \n",
      "            +-------------------------------+            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                 +--------------------+                  \n",
      "                 | ChatPromptTemplate |                  \n",
      "                 +--------------------+                  \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                      +----------+                       \n",
      "                      | ChatGroq |                       \n",
      "                      +----------+                       \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                  +-----------------+                    \n",
      "                  | StrOutputParser |                    \n",
      "                  +-----------------+                    \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                      +----------+                       \n",
      "                      | ChatGroq |                       \n",
      "                      +----------+                       \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                  +-----------------+                    \n",
      "                  | StrOutputParser |                    \n",
      "                  +-----------------+                    \n",
      "                            *                            \n",
      "                            *                            \n",
      "                            *                            \n",
      "                +-----------------------+                \n",
      "                | StrOutputParserOutput |                \n",
      "                +-----------------------+                \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RunnalbeLambda \n",
    "\n",
    "* Converts normal python functions into runnalbe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# Let's create two simple lambda function \n",
    "\n",
    "find_sum = lambda x: sum(x)\n",
    "find_sq = lambda x: x**2\n",
    "\n",
    "# We can't pipe this in our chain, becaure it aren't runnalbe object, two convert to runnable object, we use RunnableLambda \n",
    "from langchain_core.runnables import RunnableLambda \n",
    "\n",
    "runnalbe_sum = RunnableLambda(find_sum)   #You can also create a function ans pass it here \n",
    "runnalbe_sq = RunnableLambda(find_sq)\n",
    "\n",
    "# print(runnalbe_sum.invoke([1, 2, 3])) ## You will get the same output as before \n",
    "lambda_runnalbe = runnalbe_sum | runnalbe_sq \n",
    "\n",
    "print(lambda_runnalbe.invoke([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+  \n",
      "| LambdaInput |  \n",
      "+-------------+  \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "   +--------+    \n",
      "   | Lambda |    \n",
      "   +--------+    \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "   +--------+    \n",
      "   | Lambda |    \n",
      "   +--------+    \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+--------------+ \n",
      "| LambdaOutput | \n",
      "+--------------+ \n"
     ]
    }
   ],
   "source": [
    "lambda_runnalbe.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296\n"
     ]
    }
   ],
   "source": [
    "#you can also create a runnables using chains \n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def runnable_multiple(x): \n",
    "    return x*x \n",
    "\n",
    "new_chain = lambda_runnalbe | runnable_multiple \n",
    "\n",
    "print(new_chain.invoke([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Assign in RunnablePassThrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'first_letter': 'h', 'second_letter': 'i'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It allows us to include additional keys to the dictionary we are passing through \n",
    "# If you want to get some information from the output / input of some other chain, use this,\n",
    "\n",
    "RunnablePassthrough().invoke({\"input\": \"hi\"}) # this is a normal function, but I want [h] in [first letter], [i] in [second letter] key\n",
    "\n",
    "grab_first_letter = lambda x: x['input'][0] #input is the key in our RunnalbePassthrough \n",
    "grab_second_letter = lambda x: x['input'][1]\n",
    "\n",
    "RunnablePassthrough.assign(first_letter=grab_first_letter, second_letter=grab_second_letter).invoke({'input': \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ItemGetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# It tries to retrieve the item in the given object, if the object supports itemgetter thunder method \n",
    "\n",
    "itemgetter(0)(\"hi\")\n",
    "itemgetter('hello')({\"hello\": \"hi\"})\n",
    "itemgetter(2)([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_getter = RunnableLambda(itemgetter(\"chat_history\")).invoke({\"chat_history\": \"how are you darling\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Adding Multiple Runnalbes ( Example Real world )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add memory to our llms using LCEL while using all we learnt \n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.memory import ConversationSummaryMemory \n",
    "\n",
    "template_for_answer = \"\"\"\n",
    "You're a helpful AI Assistant, based on the given chat_hisotry you have to answer, if you don't know just say I don't know. \n",
    "\n",
    "conversation history: \n",
    "{chat_history}\n",
    "\n",
    "Human: \n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "template_for_answer = PromptTemplate.from_template(template_for_answer)\n",
    "memory = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "## Rather than immediately creating a chain, let's invoke one by one and build at last\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(  chat_history=RunnableLambda(memory.load_memory_variables) | RunnableLambda(itemgetter(\"chat_history\")) )\n",
    "    | template_for_answer\n",
    "    | llm \n",
    "    | StrOutputParser() \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Can you give me the intersting fact?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = final_chain.invoke({\"question\": question})\n",
    "memory.save_context(inputs= {\"input\": question}, outputs ={\"output\": out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def final_chain(question): \n",
    "\n",
    "    final_chain = (\n",
    "        RunnablePassthrough.assign(  chat_history=RunnableLambda(memory.load_memory_variables) | RunnableLambda(itemgetter(\"chat_history\")) )\n",
    "        | template_for_answer\n",
    "        | llm \n",
    "        | StrOutputParser() \n",
    "        )\n",
    "    \n",
    "    out = final_chain.invoke({\"question\": question})\n",
    "    memory.save_context(inputs= {\"input\": question}, outputs ={\"output\": out})\n",
    "\n",
    "    return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on our conversation history, your name is Aravind. I'm here to help answer your questions to the best of my ability. If I don't know something, I'll let you know. Is there something specific you'd like to know about octopuses or any other topic?\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\"What's my naem?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
